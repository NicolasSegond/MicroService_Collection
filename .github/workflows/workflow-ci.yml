name: CI / CD Pipeline


on:
  push:
    branches: [ "main", "develop" ]
  pull_request:
    branches: [ "main", "develop" ]

env:
  NODE_VERSION: 22
  FRONT_COVERAGE: "frontend/coverage"


jobs:
  build-and-test:
    name: Build and Test Marketplace Frontend
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          cache-dependency-path: ./frontend/package-lock.json

      - name: Install dependencies
        working-directory: ./frontend
        run: npm install

      - name: Run ESLint
        working-directory: ./frontend
        run: npm run lint

      - name: Tests unitaires + couverture (Vitest)
        working-directory: ./frontend
        run: npm run test -- --run --coverage --coverage.reporter="lcov"

      - name: Prépare le rapport de couverture back (LCOV)
        working-directory: ./frontend
        run: |
          test -f coverage/lcov.info || (echo "Pas de LCOV back, création d'un stub" && mkdir -p coverage && printf "TN:\nSF:dummy.js\nDA:1,0\nend_of_record\n" > coverage/lcov.info)
          mv coverage/lcov.info ../${{ env.FRONT_COVERAGE }}

      - name: Artefact couverture frontend
        uses: actions/upload-artifact@v4
        with:
          name: frontend-coverage
          path: ${{ env.FRONT_COVERAGE }}
          retention-days: 7

  sonarcloud:
    name: Qualité • SonarCloud (multi-langages)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: build-and-test

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download frontend coverage artefact
        uses: actions/download-artifact@v4
        with:
          name: frontend-coverage
          path: ${{ env.FRONT_COVERAGE }}

      - name: Scan SonarCloud (PHP + JS/TS)
        uses: SonarSource/sonarcloud-github-action@v2
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          args: >
            -Dsonar.projectKey=NicolasSegond_MicroService_Collection
            -Dsonar.organization=nicolassegond
            -Dsonar.sources=frontend/src
            -Dsonar.tests=frontend/src/__tests__,frontend/src/__mocks__
            -Dsonar.exclusions=**/vendor/**,**/var/**,**/node_modules/**,**/dist/**,**/__tests__/**,**/__mocks__/**
            -Dsonar.javascript.lcov.reportPaths=${{ env.FRONT_COVERAGE }}

  zap-local:
    name: Security • ZAP Scan (Local)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Decrypt environment file
        env:
          ENCRYPTION_KEY: ${{ secrets.ENCRYPTION_KEY }}
        run: |
          openssl enc -aes-256-cbc -d -pbkdf2 -in .env.enc -out .env -pass pass:"$ENCRYPTION_KEY"

      - name: Start services (CI mode - no auth)
        run: |
          docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d --build

      - name: Wait for services
        run: |
          echo "Waiting for Keycloak..."
          timeout 180 bash -c 'until curl -sf http://localhost:8080/health/ready; do sleep 5; done'
          
          # Wait for Traefik
          echo "Waiting for Traefik..."
          timeout 120 bash -c 'until docker compose exec -T traefik traefik healthcheck; do sleep 5; done'
          echo "Traefik is ready!"
          
          sleep 5
          echo "All services ready!"

      - name: ZAP Baseline Scan
        run: |
          # Create writable directory structure for ZAP
          mkdir -p zap-wrk/.ZAP zap-wrk/reports
          
          # Copy ZAP config files to writable location
          cp .zap/rules.tsv zap-wrk/rules.tsv
          cp .zap/zap.yaml zap-wrk/zap.yaml
          
          # Update zap.yaml URLs to use traefik hostname (internal Docker network)
          sed -i 's|http://localhost:8000|http://traefik:80|g' zap-wrk/zap.yaml
          
          # Change ownership to zap user (UID 1000) inside container
          sudo chown -R 1000:1000 zap-wrk
          
          # Get the Docker network name created by docker-compose
          NETWORK_NAME=$(docker network ls --format '{{.Name}}' | grep -E 'app-network' | head -1)
          echo "Using network: $NETWORK_NAME"
          
          # Show the zap.yaml content for debugging
          echo "=== ZAP Config ==="
          cat zap-wrk/zap.yaml
          
          # Run ZAP with Automation Framework (uses zap.yaml)
          docker run --rm \
            --network "${NETWORK_NAME:-microservice_collection_app-network}" \
            -v ${{ github.workspace }}/zap-wrk:/zap/wrk:rw \
            -v ${{ github.workspace }}/zap-wrk:/home/zap:rw \
            -t ghcr.io/zaproxy/zaproxy:stable \
            zap.sh -cmd \
              -autorun /zap/wrk/zap.yaml \
            || echo "ZAP scan completed with findings"
          
          echo "=== ZAP Reports ==="
          ls -la zap-wrk/
          ls -la zap-wrk/reports/ || true

      - name: Upload ZAP Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: zap-security-report
          path: zap-wrk/reports/
          if-no-files-found: warn

      - name: Stop services
        if: always()
        run: docker compose -f docker-compose.yml -f docker-compose.ci.yml down -v